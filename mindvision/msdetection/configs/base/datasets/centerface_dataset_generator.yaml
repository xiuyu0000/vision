# Copyright 2021 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
data_loader:
  train:
    dataset:
      type: GeneratorDataset
      source:
        type: CenterfaceDataset
        annot_path: '/data/centerface/annotations/train_wider_face.json'
        img_dir: '/data/centerface/images/train/images/'
        split: train
        max_objs: 64
      sampler:
        type: DistributedSampler
        rank: 0
        shuffle: True
        num_replicas: 1
      column_names: [ "image", "annotation" ]
      num_parallel_workers: 16
    map:
      operations:
        - type: CenterFormat
        - type: Decode
          decode_mode: C
        - type: CenterfaceCropPreprocess
          max_size: 12000
          inf_distance: 9999999
          anchor_idx: 5
          anchors: [16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 128, 256, 512]
        - type: CenterfaceResize
          scale: 0.4
          split: train
          flip: 0.5
          rand_crop: True
          shift: 0.1
          output_res: 128
          input_res: 512
          rotate: 0
        - type: StaticNormalize
          mean: [0.40789654, 0.44719302, 0.47026115]
          std: [0.28863828, 0.27408164, 0.27809835]
        - type: ColorAug
          eig_val: [0.2141788, 0.01817699, 0.00341571]
          eig_vec: [[-0.58752847, -0.69563484, 0.41340352],
                    [-0.5832747, 0.00994535, -0.81221408],
                    [-0.56089297, 0.71832671, 0.41158938]]
          scale: 0.1
        - type: CenterfaceBboxPreprocess
          flip_idx: [[0, 1], [3, 4]]
          output_res: 128 #192 #200
          num_classes: 1
          num_joints: 5
          max_objs: 64
        - type: Transpose
        - type: Collect
          output_orders: ["image", "hm", "reg_mask", "ind", "wh", "wight_mask", "hm_offset", "hps_mask", "landmarks"]
          output_type_dict:
            image: float32
            hm: float32
            reg_mask: float32
            ind: float32
            wh: float32
            wight_mask: float32
            hm_offset: float32
            hps_mask: float32
            landmarks: float32
      input_columns: ["image", "annotation"]
      output_columns: ["image", "hm", "reg_mask", "ind", "wh", "wight_mask", "hm_offset", "hps_mask", "landmarks"]
      column_order: ["image", "hm", "reg_mask", "ind", "wh", "wight_mask", "hm_offset", "hps_mask", "landmarks"]
      python_multiprocessing: True
    batch:
      batch_size: 8
      drop_remainder: True

  eval:
    dataset:
      type: GeneratorDataset
      source:
        type: CenterfaceDataset
        annot_path: '/data/centerface/ground_truth/wider_face_val.mat'
        img_dir: "/data/centerface/images/val/images/"
        split: test
        save_path: 'mat_val.json'
      sampler:
        type: DistributedSampler
        rank: 0
        shuffle: True
        num_replicas: 1
      column_names: [ "image", "image_id" ]
      num_parallel_workers: 1
    map:
      operations:
        - type: Format
          is_infer: True
          pad_max_number: None
        - type: Decode
          decode_mode: C
        - type: CenterfaceResize
          flip: 0.5
          rand_crop: True
          shift: 0.1
          output_res: 128
          input_res: 512
          rotate: 0
          input_h: 832 #800
          input_w: 832 #800
          scale: 0.999
          fix_res: True
          split: test
          down_ratio: 4
        - type: StaticNormalize
          mean: [0.408, 0.447, 0.470]
          std: [0.289, 0.274, 0.278]
        - type: Transpose
        - type: Collect
          output_orders: [ "image", "image_id", "c" , "s", "out_height", "out_width" ]
          output_type_dict:
            image: float32
            image_id: int32
            c: float32
            s: float64
            out_height: int32
            out_width: int32
      input_columns: [ "image", "image_id"]
      output_columns: [ "image", "image_id", "c" , "s", "out_height", "out_width" ]
      column_order: [ "image", "image_id", "c" , "s", "out_height", "out_width" ]
    batch:
      batch_size: 1
      drop_remainder: True

  prefetch_size: 8
  thread_num: 0
  group_size: 1
